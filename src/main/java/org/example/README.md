1. Сортировка (базовое)
Алгоритмы сортировки -- это очень важный класс алгоритмов, который занимается упорядочиванием элементов в массиве (списке). 
Проблема в том, что самые простые алгоритмы, очевидные в реализации, одновременно и самые неэффективные, медленные. 
Их сложность начинается с O(n^2) и выше, а на практике типичны задачки, когда надо отсортировать наборы 
из миллионов или миллиардов значений.
К простым алгоритмам сортировки обычно относят три типа алгоритмов (рассматриваем упорядочивание по возрастанию).

1. Сортировка выбором

Двигаясь по массиву с начала, берём очередной i-й элемент и меняем его местами с минимальным элементом 
в оставшейся последовательности, начиная с элемента i+1, если этот минимальный элемент меньше текущего.

Например, у нас есть массив (4,3,1,2).
Меняем 0-й элемент 4 и 1:
1,3,4,2
Следующий, 1-й элемент 3 -- меняем с элементом 2:
1,2,4,3
Следующий, 2-й элемент 4 -- меняем с последним элементом 3:
1,2,3,4
Минус, что надо постоянно выполнять поиск минимального элемента.

2. Сортировка пузырьком

Организуем бесконечный цикл, внутри которого выполняем последовательный пробег по всем элементам массива, 
кроме последнего, проверяя, больше ли текущий элемент следующего. Если больше, меняем их местами. 
Таким образом все меньшие элементы постепенно "всплывают" вверх (к началу массива) как пузырьки.
Если по окончании пробега ни одного обмена элементов не было, значит упорядоченность достигнута, и сортировка закончена.

Например, у нас есть массив (4,3,1,2).
Делаем первый пробег:
4,3,1,2 - 3,4,1,2 - 3,1,4,2 - 3,1,2,4
Второй пробег:
3,1,2,4 - 1,3,2,4 - 1,2,3,4
Третий пробег:
1,2,3,4 - закончили.
Недостаток -- в большом количестве итераций.

Третий тип -- сортировка вставками, будет рассмотрен в следующем занятии.

3. Задание

3.1. Реализуйте функцию для одного шага сортировки выбором, 
которая получает на вход массив целых чисел (передаётся по ссылке) и номер элемента i (i >= 0), 
и меняет в этом массиве i-й элемент местами с минимальным элементом в оставшейся части массива, начиная с элемента i+1.

Заголовок функции (псевдокод):
SelectionSortStep( int array[], int i )

3.2. Реализуйте функцию для одного шага сортировки пузырьком, которая получает на вход массив целых чисел (передаётся по ссылке), 
и выполняет один пробег по массиву от начала к концу, меняя местами каждые два элемента i и i+1, если i-й элемент больше i+1-го. 
Функция возвращает true, если по окончании пробега не было ни одного обмена элементов.

bool BubbleSortStep( int array[] )

Решение: SortLevelForSolving_001

2. Сортировка вставками
Это третий вид простых базовых сортировок, выполняющихся за O(n^2).

Двигаясь по массиву с первого элемента, берём очередной i-й элемент 
и ставим его в предыдущую последовательность (от нуля до i-1) так, 
чтобы в этой последовательности сохранялась упорядоченность.

Например, у нас есть массив (4,3,1,2).
Начинаем с элемента 3 -- вставляем его в начало:
3,4,1,2
Следующий элемент 1 - вставляем его первым перед 3,4:
1,3,4,2
Последний элемент 2 -- вставляем его после 1:
1,2,3,4
Главный недостаток этого способа -- необходимость часто сдвигать большие последовательности в массиве, 
особенно если в конце хранятся маленькие значения.

Задание

Реализуйте предварительный алгоритм для сортировки вставками с дополнительным параметром -- шагом сортировки.

Например, если есть массив (7,6,5,4,3,2,1), и мы задаём шаг сортировки 3, то мы в цикле, начиная с i-го элемента, 
сортируем в массиве только те последующие элементы, которые отстоят друг от друга на этот шаг.

Исходный массив будет меняться так:

i=0
7,6,5,4,3,2,1
1,6,5,4,3,2,7
i=1
1,3,5,4,6,2,7
i=2
1,3,2,4,6,5,7
i=3
1,3,2,4,6,5,7
Ещё раз:
если i=0 и шаг=3, то соответственно,
из 7,6,5,4,3,2,1 выделили 7,4,1 через шаг 3
отсортировали, получили 1,4,7
и с учётом их оригинальных позиций в массиве и получилось 1,6,5,4,3,2,7 .

Если шаг равен 1, тогда алгоритм будет работать стандартным образом.

Шаг сортировки понадобится далее, при реализации эффективных алгоритмов сортировки.

Пока данный алгоритм не выполняет полную сортировку, он только готовит массив к следующему шагу.

О важности выбора правильного алгоритма, и почему их так много.
Возьмём конкретный случай, когда надо отсортировать два миллиона целых чисел.
Сортировка вставками будет тут работать за O(2*N^2), а сортировка слиянием, которую мы изучим позже, за O(50*N*log N).
Пусть у нас имеется два компьютера: А с производительностью 10 миллиардов инструкций в секунду, 
и Б с производительностью 10 миллионов инструкций в секунду. 
На компьютере А мы будем применять сортировку вставками, а на компьютере Б -- сортировку слиянием. 
Тогда на компьютере А сортировка продлится примерно 5,5 часов, 
а на компьютере Б (который в тысячу раз медленнее) -- примерно 20 минут.

Задание

Реализуйте функцию для одного шага сортировки вставкой (по возрастанию), 
которая получает на вход массив целых чисел (передаётся по ссылке), размер шага (>= 1) и номер элемента i (i >= 0), 
с которого выполняется один шаг сортировки.

Заголовок функции (псевдокод):

InsertionSortStep( int[] array, int step, int i )
Например, вызов InsertionSortStep( [1,6,5,4,3,2,7], 3, 1 ) изменит входной массив на [1,3,5,4,6,2,7].

Решение: SortLevelForSolving_002


3. Сортировка Шелла

Сортировка Шелла -- это скорее эвристический алгоритм, который в среднем показывает неплохую скорость порядка O(n * (log n)^2). 
При этом, что очень важно, даже если на вход поступает самый "плохой" вариант для сортировки, 
данный алгоритм справляется с ним примерно за то же время. 
Поэтому сортировку Шелла можно всегда использовать как палочку-выручалочку, и только если в конкретной задаче он работает плохо, 
переходить к более сложным эффективным алгоритмам.

Идея сортировки Шелла довольно проста и заключается в том, что если у нас элементы упорядочены наихудшим образом, 
перемещение правых элементов влево по одному шагу может потребовать слишком много ресурсов. 
Сортировка Шелла придерживается такой схемы: сперва мы сортируем элементы с шагом N (как мы делали в прошлом занятии), 
затем уменьшаем этот шаг, снова сортируем, и так далее до шага 1. 
При этом, за счёт того, что после каждого прохода данные у нас немного упорядочиваются, 
каждый следующий проход выполняется значительно быстрее -- фактически стремится к O(n).

Какую последовательность шагов брать? 
Существует, например, рекомендованная интервальная последовательность Кнута -- ..., 364, 121, 40, 13, 4, 1. 
Эта последовательность генерируется по формуле

N(i) = 3 * N(i-1) + 1
где N(0) - это самый первый шаг, единица.

Например, у нас есть массив из 15 элементов. 
Тогда мы начинаем с шага 13 и выполняем сортировку так (считаем первый элемент массива 0-м):

Проход 1.
Сортируем:
0-й и 13-й элементы
1-й и 14-й элементы

Проход 2.
Теперь переходим к шагу 4:
Сортируем:
0-й, 4-й, 8-й, 12-й элементы
1-й, 5-й, 9-й, 13-й элементы
2-й, 6-й, 10-й, 14-й элементы
3-й, 7-й, 11-й элементы

Проход 3.
Теперь последний шаг 1 -- просто сортируем
классическим способом все элементы подряд.

Задание.

Дополните предыдущее задание функцией, которая по параметру n >= 0 (размер массива) вычислит нужную интервальную последовательность 
целых чисел (список для Python, List для C#, ArrayList для Java).

Заголовок функции (псевдокод):

KnuthSequence( int array_size )
Например, вызов KnuthSequence(15) вернёт список [13, 4, 1].

Решение: SortLevelForSolving_003


4. Алгоритм разбиения массива
   Алгоритм разбиения массива на две группы -- это промежуточный шаг к классической быстрой сортировке, которая существенно обгоняет сортировку Шелла на больших наборах данных (от десятков тысяч элементов).

Смысл разбиения -- разделить массив (мутабельный список) на две группы, в левой из которых собраны его элементы, меньшие некоторого порогового значения, называемого опорным, а в правой части собраны элементы, большие этого опорного значения. Выбор опорного значения -- достаточно тонкий момент, который реализуется в зависимости от решаемой задачи, и сам алгоритм тоже зависит от способа такого выбора.

Мы рассмотрим вариант, когда в качестве опорного значения выбирается центральное значение в массиве. Подразумевается, что значение опорного элемента в массиве ровно одно, и в целом, в массиве нету одинаковых элементов (в противном случае используются более сложные схемы сортировки, когда массив разбивается на три группы, и одинаковые значения опорного элемента включаются в третью группу).

Алгоритм разбиения массива M такой:

0. В переменную N заносим опорное значение, которое хранится в массиве по индексу, равному (длина массива / 2), 
    где / -- целочисленное деление (7/2=3). Запоминаем также индекс опорного элемента.

1. В переменную i1 заносим 0 (индекс первого элемента), а в переменную i2 - длину массива M минус один (индекс последнего элемента).

2. Пока значение M[ i1 ] меньше N , увеличиваем i1 на 1.

3. Пока значение M[ i2 ] больше N , уменьшаем i2 на 1.

4. Если i1 = i2 - 1 и M[i1] > M[i2], то меняем M[i1] и M[i2] местами, и возвращаемся к п. 0.

5. Если i1 = i2 или (i1 = i2 - 1 и M[i1] < M[i2]), то возвращаем индекс финальной позиции опорного элемента, и прекращаем работу.

6. К данному пункту M[i1] хранит элемент, больший или равный опорному, а M[i2] хранит элемент, меньший или равный опорному. 
   Меняем их местами (если один из них -- опорный элемент, надо обновить его новый индекс), и переходим к п.2.

Задание.

Напишите функцию ArrayChunk, которая получает в качестве параметра массив (по ссылке), выполняет разбиение его на две группы, 
и возвращает индекс опорного элемента.

Заголовок функции (псевдокод):

int ArrayChunk( int[] M )
Например, вызов ArrayChunk( [7,5,6,4,3,1,2] ) вернёт 3, а массив примет значение [2,1,3,4,6,5,7].

Решение: SortLevelForSolving_004


5. Быстрая сортировка Хоара
   Это самый популярный на сегодня алгоритм сортировки, который показывает сложность O(N * log N). 
Он основан на алгоритме разбиения, когда мы делим сортируемый массив/список на две группы, 
к которым несколько парадоксально применяется рекурсия.

Алгоритм быстрой сортировки -- это рекурсивное применение его самого к каждой из групп, выделяемых с помощью алгоритма разбиения.

Остаётся вроде бы открытым вопрос: а в какой момент выполняется сама сортировка? 
Но вспомним, что алгоритм разбиения уже делит массив на группы, в одной из которых собраны все меньшие, 
а в другой -- все большие элементы. 
Таким образом сама сортировка происходит в некотором смысле автоматически, без явных упорядочиваний.

Рекурсивная функция QuickSort() получает на вход массив (по ссылке) и два параметра: 
left и right, которые по сути имеют смысл левого и правого индексов в алгоритме разбиения. 
Сперва мы проверяем, если left и right равны, значит сортировка закончена (массив из одного элемента упорядочен по определению).

В противном случае мы сначала вызываем из прошлого занятия алгоритм разбиения для диапазона значений left .. right, 
который вносит соответствующие изменения в этот диапазон (разбивает его на два поддиапазона), и возвращает индекс N опорного элемента.
Теперь естественным образом слева от опорного элемента будут находиться заведомо меньшие элементы, 
а справа заведомо большие. 
Мы можем считать, что наш опорный элемент уже находится в "отсортированном" месте, и из дальнейшего разбиения его можно исключить.

Поэтому двумя следующими шагами после разбиения мы просто вызываем

QuickSort( array, left, N-1 )
и
QuickSort( array, N+1, right )
где N -- это индекс опорного элемента.
Задание.

Напишите функцию QuickSort(), которая получает в качестве параметра массив (по ссылке) и два индекса, выполняет разбиение его на два диапазона (и опорный элемент), и вызывает саму себя для каждого из диапазонов.

Заголовок функции (псевдокод):

void QuickSort( int[] array, int left, int right )

Решение: SortLevelForSolving_005


6. Элиминация хвостовой рекурсии
Оригинальный алгоритм QuickSort в существенной степени завязан на схему разбиения массива (выбор опорного элемента). 
Мы рассмотрели схему с двумя индексами (разбиение Хоара), она считается весьма хорошей, 
хотя и нестабильной (сильно зависящей от порядка входных данных). 
Широко известно также разбиение Ломуто из классической книги по алгоритмам Кормена: 
в качестве опорного выбирается последний элемент, и соответственно, второй индекс i2 у нас всегда фиксирован, 
а "поднимается" только один первый индекс i1. Этот метод плохо действует например, когда в массиве много повторяющихся значений.

Хорошо показывает себя даже случайный выбор опорного элемента, 
потому что удачным считается попадание опорного элемента в центральные 50% элементов массива. 
Но фактически для любого фиксированного соотношения между размерами разделённых частей сохраняется сложность O(N * log N). 
Самый плохой случай -- когда в качестве опорного выбирается максимальный (или минимальный, в зависимости от порядка сортировки) элемент, 
что приводит к делению массива на размеры 1 и n-1 и фактически к n-1 вызовам операции разделения. 
Тогда итоговая сложность получится O(N * N), а глубина рекурсии достигнет n вызовов, 
что при больших массивах чревато переполнением стека вызова.

В этой связи иногда применяется (если позволяет конкретный язык программирования) так называемая элиминация 
(устранение) хвостовой рекурсии. Она основана на специфике компиляции вызовов функций и предполагает, 
что рекурсивный вызов выполняется в коде рекурсивной функции самым последним. 
В таком случае стек для хранения точки возврата обратно в функцию можно не использовать, 
потому что возвращаться уже никуда не надо. 
Более того, код на основе хвостовой рекурсии может быть достаточно просто переведён в нерекурсивный.

Кроме того, конечно, рекурсивный вызов в случае элиминации должен гарантированно происходить однократно. 
Если у нас два или более рекурсивных вызовов в процессе работы функции, 
то невозможно предсказать в произвольный момент времени, по какому из этих вызовов разворачивается текущая рекурсия 
(куда мы в итоге вернёмся где-то там выше, в самый исходный вызов), 
поэтому точку возврата из каждого вызова надо запоминать в стеке новую, и стек вызовов быстро растёт. 
А когда рекурсивный вызов только один, то достаточно всего одной точки возврата, 
фактически это не рекурсия получается, а просто итерации, так как у нас не дерево рекурсивных вызовов, а всего одна линейная цепочка. 
Мы всегда гарантированно знаем, в какую точку функции вернёмся из рекурсии.
Рекурсивные вызовы можно разнести по разным условным веточкам в теле функции, 
главное, чтобы они гарантированно не выполнялись вместе.

Примеры на псевдокоде обычного рекурсивного факториала:

int factorial (int n)
if(n == 0)
return 1
return n*factorial(n-1)
Почему этот код без хвостовой рекурсии? Потому что порядок вычисления n*factorial(n-1) в конкретном языке вполне может быть таким, 
что первым выполняется рекурсивный вызов, 
и только потом умножение вычисленного значения на n -- то есть рекурсия не будет последним вызовом в этой функции.

Факториал с элиминацией хвостовой рекурсии запишется так:

int factorial(int n, int a)
if(n < 0) return 0
if(n == 0) return 1
if(n == 1) return a
return factorial(n - 1, n * a)
Задание.

Реализуйте алгоритм быстрой сортировки Хоара QuickSort() из прошлого занятия с хвостовой рекурсией.
Заголовок функции (псевдокод):

Решение: SortLevelForSolving_006


7. Поиск порядковых статистик
Иногда требуется узнать, имея исходный неотсортированный массив, какой элемент в этом массиве, 
когда он будет отсортирован, находится в k-й позиции.

Такой k-й элемент называется порядковая статистика.

Например, имеется массив 3,5,2,4,1, и нам нужна 0-я порядковая статистика (начиная с нуля).
В отсортированном виде этот массив будет таким: 1,2,3,4,5, и соответственно элемент в 0-й позиции -- это 1.
А 4-я порядковая статистика для массива 3,5,2,4,1, соответственно, будет 5.

Однако выполнять полную сортировку для поиска порядковой статистики нежелательно, поэтому был придуман специальный алгоритм.

Для поиска k-й порядковой статистики с помощью алгоритма разбиения массива применяется следующий алгоритм:

1. Выбираем левую и правую границы диапазона L и R, равные индексам начального и конечного элементов в массиве 
   (исходно это будет 0 и длина массива - 1).

2. Выполняем разбиение подмассива в диапазоне L .. R (включая L и R) исходного массива, 
   в качестве опорного элемента выбирая элемент в позиции (R+L)/2. Получаем новый индекс N этого опорного элемента. 
   Если N равно k, значит мы нашли искомое, заканчиваем алгоритм.

3. Если N меньше k, значит выбранный нами в качестве опорного элемент меньше по значению искомого. 
   Тогда задаём L = N + 1, и переходим к п.2.

4. Если N больше k, значит выбранный нами в качестве опорного элемент больше по значению искомого. 
   Тогда задаём R = N - 1, и переходим к п.2.

Как уже говорилось, мы можем выбирать опорный элемент даже случайным образом. 
На его основании можно создать и рандомизированную модификацию Quick-Sort, 
когда на каждом шаге вышеописанного алгоритма в очередном диапазоне мы выбираем не средний, 
а снова случайный элемент в качестве опорного.

Математическое ожидание времени работы остаётся O(N * log N), этому есть строгое доказательство, 
а "очевидное" рассуждение такое, что при неудачных случайных значениях опорного элемента мы будем получать O(N*N), 
а при удачных O(N), и итоговое среднее значение стремится к O(N * log N).
Однако в общем случае, конечно, когда данные могут быть распределены в выборке неравномерно, 
желательно всё же получать точную медиану, но это непросто. 
Был придуман компромиссный алгоритм, который предполагает, 
что k-j -й и k+j - й (например, k-1 и k+1) порядковые статистики будут достаточно близки к искомому значению, 
и задаётся разброс, насколько далеко разрешается отклоняться от k по отношению к общему числу элементов. 
Существует метод Манро-Патерсона, 
который таким способом быстро вычисляет приближённую медиану с помощью дополнительного буфера в памяти, 
и он в большинстве случаев показывает очень хорошие результаты.

И наконец, был разработан BFPRT-алгоритм (Мануэль Блюм и др.), который гарантирует поиск k-й статистики за линейное время O(N). 
Достигается это, конечно, усложнением используемой структуры хранения данных. Чтобы он работал эффективно, 
желательны достаточно объёмные массивы, от тысячи элементов. Общая его идея в том, что количество чисел, меньших опорного элемента, 
должно быть не меньше 3 * N / 10, и количество чисел, больших опорного элемента, должно быть не более 3 * N / 10, из чего, 
утверждают авторы, и достигается линейное время.

Алгоритм:

1. Входной массив из n элементов разбивается на группы по 5 (или большее нечётное количество) элементов. 
   В последней группе будет (n % 5) элементов (в частности, ноль).

2. Каждая группа сортируется, и для неё определяется медиана.

3. Находится медиана для всех медиан - s. Она специфична тем, что в массиве будет не менее 25% элементов, меньших её, 
   и не менее 25% элементов, больших её.

4. Разбиение массива на основе s потребует анализа (сравнения) только половины элементов, 
   так как две четверти уже отсортированы относительно s. Если позиция i медианы s равна k, то искомый элемент найден.

Иначе применяем этот алгоритм к левой части разбиения (если i больше k), или к правой в противном случае.

Так как мы на каждом шаге отбрасываем как минимум четверть (а в лучшем случае три четверти) элементов, 
то получаем гарантированное линейное время.

Задание.

Реализуйте алгоритм (самый первый в этом занятии) одного шага поиска k-й статистики KthOrderStatisticsStep(). 
Эта функция получает на вход массив (по ссылке), границы L и R в пределах массива, 
и требуемую позицию порядковой статистики k, 
и вычисляет новые границы (возможно, одинаковые, если k-я статистика найдена). 
Результат возвращается как список (список для Python, List для C#, ArrayList для Java) из двух целых чисел -- новые L и R.

Заголовок функции (псевдокод):

list KthOrderStatisticsStep( int[] Array, int L, int R, int k )

Решение: SortLevelForSolving_007


8. Сортировка слиянием (Merge-Sort)
   Этот способ сортировки -- классический пример рекурсивной компактности при использовании метода "разделяй и властвуй".

На первом шаге "разделяй" мы делим массив на две примерно равные части (хотя их равность не очень принципиальна), 
после чего сортируем их по этому же самому алгоритму. 
Рекурсия заканчивается, когда мы получаем массив из одного элемента, который, очевидно, упорядочен.

На втором шаге "властвуй", получив два отсортированных массива, мы начинаем их сливать: 
определяем, какой из двух очередных элементов (по одному из каждого массива) наименьший 
(или наибольший, в зависимости от порядка упорядочивания), 
"выбираем" его из соответствующего массива (например, сдвигаем индекс текущего элемента к следующему) и добавляем в результат.
Когда остаётся только один непустой массив, записываем в хвост результата его содержимое целиком.

Такой алгоритм хорошо подходит для реализации на параллельных архитектурах, 
так как сортировку подмассивов можно выполнять полностью независимо, 
а минус его, что он справляется примерно одинаково как со случайными данными, так и с почти отсортированными.

Оценка сложности
Так как на каждом шаге мы делим массив надвое, получаем log2 N итераций. 
Так как каждая итерация доходит до каждого отдельного элемента, получается итоговая сложность O(N * log N).

K-way Merge-Sort
В общем случае мы можем делить массив не на два, а на k подмассивов. 
Общая схема работы не меняется: получив результат из k отсортированных подмассивов 
(упорядоченных в том же порядке, в каком ожидается упорядоченность результата), 
мы поочерёдно сканируем их и выбираем наименьший (или наибольший, в зависимости от ожидаемой упорядоченности результата) 
элемент для добавления в результирующий массив. 
С одной стороны, выигрыша мы фактически не получаем, однако на практике имеется большая область, 
для которой алгоритм K-way Merge-Sort, особенно когда k достаточно велико, оказался весьма полезным. 
Это ситуация, когда сами k массивов огромны, и хранятся не в оперативке, 
а в медленной "внешней памяти" (на жёстких дисках или в сети). 
Но при этом они как правило отсортированы -- например, это могут быть коннекторы к различным базам данных, 
которые (базы) выдают наборы уже в отсортированном виде, и главная задача тут эффективно их объединить.

Казалось бы, сложного здесь ничего нету: так же пробегаемся по всем k входным данным, берём текущие элементы, сравниваем, 
ищем минимальное например, выдаём в результат, и т. д. 
Однако добавлять к общей сложности ещё k итераций на каждый элемент оказывается накладным, 
поэтому были придуманы различные более эффективные алгоритмы, или даже эвристики. 
Так, можно создать k буферов в оперативной памяти, и подкачивать в них данные из файлов уже большими порциями. 
Большой выигрыш дают подходы, когда в дополнение к "сырым" данным мы храним ещё и мета-информацию, например, индексы сортировки.

Очевидный недостаток данного подхода в том, что результат надо хранить в массиве, 
и если на вход подаётся много крупных массивов, то и результирующий набор данных получается очень большой, 
но при этом он по сути временный. Поэтому были разработаны алгоритмы сортировки слиянием без использования дополнительной памяти, 
достаточно эффективные, но весьма сложные, например: https://habr.com/post/138146/

Основная их идея в том, что мы манипулируем блоками отсортированных данных непосредственно внутри исходных массивов. 
Понятно, что при этом надо иметь подходящие механизмы быстрой манипуляции большими блоками данных. 
Еще неплохие способы -- пропускать данные через сортирующие деревья, очереди с приоритетами и т. д. 
Много подобных алгоритмов, комбинирующих множество внешних входных источников с небольшим буфером оперативной памяти 
и несколькими быстрыми внешними буферами, были разработаны в середине прошлого века, 
когда компьютеры были очень ограниченными по ресурсам.

Одна из наиболее эффективных реализаций K-way Merge-Sort основана на использовании кучи (пирамиды), 
которая позволяет за O(1) получить доступ к максимальному элементу (или к минимальному, но не одновременно к ним обоим).
При этом сами k подмассивов рассматриваются как отсортированные последовательности разной длины, 
которые просто выдают очередной, текущий элемент (например, запросом очередного элемента по сети), 
к их следующим элементам мы доступ обычно не имеем.

Алгоритм такой (упорядочиваем по убыванию):
1. Загружаем k текущих значений (по одному очередному из всех k подмассивов) в кучу. 
При этом храним для каждого элемента в куче не только значение, но и номер его подмассива.
2. Выбираем максимальный элемент из кучи, выдаём его в результирующий массив. 
Из подмассива, в котором был этот элемент, извлекаем очередной элемент и добавляем в кучу.
   Такая операция потребует O(log k).
3. Повторяем шаг 2, пока куча непустая.

В ситуации, когда n много больше, чем k (входных подмасивов немного, и они длинные), 
итоговая сложность O(n * log k) стремится по сути к линейной O(n).

Задание.

Реализуйте алгоритм классической сортировки слиянием по возрастанию.

Шаг "Разделяй":

1. На вход подаётся неотсортированный массив.

2. Если в массиве один элемент, то работа алгоритма закончена: результатом будет отсортированный массив из одного элемента.

3. Разбиваем исходный массив посередине на два подмассива, и вызываем данный алгоритм последовательно два раза, для каждой из половин.

Шаг "Властвуй": К данному шагу мы имеем два отсортированных по возрастанию рабочих массива.

4. Готовим внутренний пустой массив-результат.
   Организуем последовательное сканирование каждого из двух рабочих массивов 
(например, с помощью временных индексов-счётчиков, или удалением головных элементов после их "выборки").

5. Если в обоих рабочих массивах ещё есть элементы, переходим к п. 8.

6. Если в одном из массивов остались элементы, записываем их последовательно в результирующий массив.

7. Возвращаем массив-результат как результат работы алгоритма.

8. Выбираем из двух текущих элементов рабочих массивов наименьший, и записываем его в результирующий массив. 
Сдвигаем счётчик в соответствующем рабочем массиве. Переходим к п. 5.

Реализуйте по данному алгоритму рекурсивную функцию MergeSort(), 
которая получает на вход исходный массив целых чисел и возвращает результат, отсортированный по вышеописанному алгоритму.
Тип параметра MergeSort() и тип её результата: список для Python, List для C#, ArrayList для Java.

Данный алгоритм -- демонстрационно-учебный. Из-за использования дополнительного внутреннего буфера и копирования массивов 
его эффективность будет низкой. 
Ключевой момент сортировки слиянием -- это именно само слияние множества массивов, 
а не сортировка поддиапазонов, которая на практике реализуется другими способами.

Решение: SortLevelForSolving_007


8. Сортировка слиянием (Merge-Sort)
Этот способ сортировки -- классический пример рекурсивной компактности при использовании метода "разделяй и властвуй".

На первом шаге "разделяй" мы делим массив на две примерно равные части (хотя их равность не очень принципиальна), 
после чего сортируем их по этому же самому алгоритму. Рекурсия заканчивается, когда мы получаем массив из одного элемента, 
который, очевидно, упорядочен.

На втором шаге "властвуй", получив два отсортированных массива, мы начинаем их сливать: 
определяем, какой из двух очередных элементов (по одному из каждого массива) наименьший 
(или наибольший, в зависимости от порядка упорядочивания), "выбираем" его из соответствующего массива 
(например, сдвигаем индекс текущего элемента к следующему) и добавляем в результат.
Когда остаётся только один непустой массив, записываем в хвост результата его содержимое целиком.

Такой алгоритм хорошо подходит для реализации на параллельных архитектурах, 
так как сортировку подмассивов можно выполнять полностью независимо, а минус его, 
что он справляется примерно одинаково как со случайными данными, так и с почти отсортированными.

Оценка сложности
Так как на каждом шаге мы делим массив надвое, получаем log2 N итераций. 
Так как каждая итерация доходит до каждого отдельного элемента, получается итоговая сложность O(N * log N).

K-way Merge-Sort
В общем случае мы можем делить массив не на два, а на k подмассивов. Общая схема работы не меняется: 
получив результат из k отсортированных подмассивов (упорядоченных в том же порядке, в каком ожидается упорядоченность результата), 
мы поочерёдно сканируем их и выбираем наименьший (или наибольший, в зависимости от ожидаемой упорядоченности результата) 
элемент для добавления в результирующий массив. С одной стороны, выигрыша мы фактически не получаем, 
однако на практике имеется большая область, для которой алгоритм K-way Merge-Sort, особенно когда k достаточно велико, 
оказался весьма полезным. Это ситуация, когда сами k массивов огромны, и хранятся не в оперативке, 
а в медленной "внешней памяти" (на жёстких дисках или в сети). Но при этом они как правило отсортированы -- например, 
это могут быть коннекторы к различным базам данных, которые (базы) выдают наборы уже в отсортированном виде, 
и главная задача тут эффективно их объединить.

Казалось бы, сложного здесь ничего нету: так же пробегаемся по всем k входным данным, берём текущие элементы, сравниваем, 
ищем минимальное например, выдаём в результат, и т. д. Однако добавлять к общей сложности ещё k итераций на каждый элемент 
оказывается накладным, поэтому были придуманы различные более эффективные алгоритмы, или даже эвристики. 
Так, можно создать k буферов в оперативной памяти, и подкачивать в них данные из файлов уже большими порциями. 
Большой выигрыш дают подходы, когда в дополнение к "сырым" данным мы храним ещё и мета-информацию, например, индексы сортировки.

Очевидный недостаток данного подхода в том, что результат надо хранить в массиве, и если на вход подаётся много крупных массивов, 
то и результирующий набор данных получается очень большой, но при этом он по сути временный. 
Поэтому были разработаны алгоритмы сортировки слиянием без использования дополнительной памяти, 
достаточно эффективные, но весьма сложные, например: https://habr.com/post/138146/

Основная их идея в том, что мы манипулируем блоками отсортированных данных непосредственно внутри исходных массивов. 
Понятно, что при этом надо иметь подходящие механизмы быстрой манипуляции большими блоками данных. 
Еще неплохие способы -- пропускать данные через сортирующие деревья, очереди с приоритетами и т. д. 
Много подобных алгоритмов, комбинирующих множество внешних входных источников с небольшим буфером оперативной памяти 
и несколькими быстрыми внешними буферами, были разработаны в середине прошлого века, 
когда компьютеры были очень ограниченными по ресурсам.

Одна из наиболее эффективных реализаций K-way Merge-Sort основана на использовании кучи (пирамиды), 
которая позволяет за O(1) получить доступ к максимальному элементу (или к минимальному, но не одновременно к ним обоим).
При этом сами k подмассивов рассматриваются как отсортированные последовательности разной длины, 
которые просто выдают очередной, текущий элемент (например, запросом очередного элемента по сети), 
к их следующим элементам мы доступ обычно не имеем.

Алгоритм такой (упорядочиваем по убыванию):
1. Загружаем k текущих значений (по одному очередному из всех k подмассивов) в кучу. 
При этом храним для каждого элемента в куче не только значение, но и номер его подмассива.
2. Выбираем максимальный элемент из кучи, выдаём его в результирующий массив. Из подмассива, 
в котором был этот элемент, извлекаем очередной элемент и добавляем в кучу.
   Такая операция потребует O(log k).
3. Повторяем шаг 2, пока куча непустая.

В ситуации, когда n много больше, чем k (входных подмасивов немного, и они длинные), 
итоговая сложность O(n * log k) стремится по сути к линейной O(n).

Задание.

Реализуйте алгоритм классической сортировки слиянием по возрастанию.

Шаг "Разделяй":

1. На вход подаётся неотсортированный массив.

2. Если в массиве один элемент, то работа алгоритма закончена: результатом будет отсортированный массив из одного элемента.

3. Разбиваем исходный массив посередине на два подмассива, и вызываем данный алгоритм последовательно два раза, для каждой из половин.

Шаг "Властвуй": К данному шагу мы имеем два отсортированных по возрастанию рабочих массива.

4. Готовим внутренний пустой массив-результат.
Организуем последовательное сканирование каждого из двух рабочих массивов 
(например, с помощью временных индексов-счётчиков, или удалением головных элементов после их "выборки").

5. Если в обоих рабочих массивах ещё есть элементы, переходим к п. 8.

6. Если в одном из массивов остались элементы, записываем их последовательно в результирующий массив.

7. Возвращаем массив-результат как результат работы алгоритма.

8. Выбираем из двух текущих элементов рабочих массивов наименьший, и записываем его в результирующий массив. 
Сдвигаем счётчик в соответствующем рабочем массиве. Переходим к п. 5.

Реализуйте по данному алгоритму рекурсивную функцию MergeSort(), 
которая получает на вход исходный массив целых чисел и возвращает результат, отсортированный по вышеописанному алгоритму.
Тип параметра MergeSort() и тип её результата: список для Python, List для C#, ArrayList для Java.

Данный алгоритм -- демонстрационно-учебный. Из-за использования дополнительного внутреннего буфера 
и копирования массивов его эффективность будет низкой. Ключевой момент сортировки слиянием -- это именно само слияние множества массивов,
а не сортировка поддиапазонов, которая на практике реализуется другими способами.


ArrayList<Integer> MergeSort(ArrayList<Integer> arr){}

Решение: SortLevelForSolving_008


9. Сортировка Heap-Sort
Двоичная куча -- это по сути очередь с приоритетом, где доступ к максимальному элементу осуществляется за O(1), 
а скорость её формирования можно считать линейной. На её основе можно реализовать алгоритм сортировки Heap-Sort. 
Особо хорошо он себя показывает, когда данные уже частично отсортированы, и на формирование самой пирамиды времени уходит немного.

Задание.

Создайте класс HeapSort, содержащий публичное поле HeapObject (тип Heap из оригинального занятия по пирамидам).

-- конструктор HeapSort() получает в качестве параметра исходный массив неотрицательных целых чисел (тип int[]), 
и последовательно и поэлементно загружает его в исходно пустую бинарную кучу HeapObject с помощью её метода Add().

-- метод GetNextMax() выдаёт максимальный элемент (целое), извлекая его из кучи, до тех пор, пока куча не пуста. 
Когда куча пуста, GetNextMax() возвращает -1.

Решение: HeapSort


10. Сортировка за линейное время
Интересный алгоритм ksort относится к классу алгоритмов, которые сортируют данные за время, близкое к O(N). 
Достигается это в каждом конкретном случае благодаря учёту контекста, в котором алгоритм выполняется.

Например, если надо отсортировать массив A из N целых положительных неповторяющихся чисел, 
которые приблизительно укладываются в диапазон, например, 1..M, где M несильно больше, чем N, 
то можно организовать массив A1 длиной M, исходные значения которого будут нули. 
Тогда помещение очередного значения i в своё отсортированное место в массиве A1 
потребует всего лишь записи ненулевого значения в A1[i-1]. 
Если числа могут повторяться, то мы можем в элементе A1[i-1] просто увеличивать счётчик соответствующего количества значений i. 
Тогда сложность ksort составит O(M).

ksort также очень удобен, даже если мы сортируем огромные массивы данных, 
но в них можно выделять небольшие последовательные диапазоны, когда сами значения хорошо подходят на роль индексов. 
Тогда процесс сортировки можно разбивать на параллельные процессы.

Схожую логику можно применять, когда вместо целых чисел используются и более сложные типы данных -- например, строки. 
Если можно придумать подходящую хэш-функцию, однозначно отражающую каждую строку в число из небольшого диапазона, 
то реализацию можно выполнить по алгоритму ksort.

Задание.

Реализуйте класс ksort, сортирующий по возрастанию за линейное время набор неповторяющихся входных данных, 
представляющих собой строки вида

AMN
где A -- это символ из диапазона abcdefgh, а MN -- две цифры.

Например: a01 b64 g99. Строки считаются упорядоченными в стандартном лексикографическом порядке (a01 < b64 < g99).

Конструктор ksort не имеет никаких параметров. Он инициализирует публичное поле items (string[], 
массив фиксированной длины для хранения результата, отсортированных по возрастанию строк) значениями null. 
Размер items должен точно соответствовать минимально необходимому для 
хранения всех потенциально возможных строк в указанном выше формате.

Публичный метод int index(string s) класса ksort вычисляет индекс строки s в массиве items, или возвращает -1, 
если строка неверного формата.

Публичный метод bool add(string s) класса ksort размещает строку s в массиве items в соответствующей позиции и возвращает true; 
а если строка некорректного формата, возвращает false.

Решение: ksort

11. Двоичный поиск
После того, как данные в массиве/списке отсортированы, 
можно существенно повысить скорость поиска в нём нужного элемента (проверка принадлежности элемента списку упорядоченных значений).

Самый простой и одновременно очень эффективный механизм поиска -- это алгоритм двоичного поиска. 
Мы не перебираем элементы подряд, а берём центральное значение из некоторого диапазона массива 
(которое сперва совпадает с его полным размером), и в зависимости от того, 
меньше, больше или равно искомое значение центрального значения в этом диапазоне, выбираем следующий диапазон (правый или левый), 
который будет меньше текущего в два раза, или возвращаем результат поиска -- положительный, 
если центральный элемент совпал с искомым, либо неудачу, если элемент не найден, а размер текущего диапазона равен единице или нулю.
Сложность этого алгоритма будет O(lg2 N).

Например, в массиве 99 чисел, исходный диапазон 0-98. Индекс центрального элемента -- 49 (99 нацело делённое на 2). 
Если искомый элемент меньше 49-го элемента, то продолжаем поиск в диапазоне 0-48, если больше, то в диапазоне 50-98, а если равно, 
то сообщаем об удачном завершении поиска.

Центральный элемент выбираем по формуле (Right+Left) / 2 (целочисленным делением). 
Границы поддиапазонов устанавливаем относительно него (левее и правее).

Задание.

Реализуйте класс BinarySearch, конструктор которого получает в качестве параметра отсортированный по возрастанию массив целых чисел int[] . 
Класс содержит публичные поля Left и Right (целый тип), которые хранят левую и правую границы текущего диапазона 
(в конструкторе им соответственно задаются 0 и длина массива-1).

Метод Step(int N) с целым параметром N (искомое значение в поиске) выполняет один шаг поиска: 
делит текущий диапазон на два, проверяет совпадение центрального элемента с искомым, 
при необходимости фиксирует завершение поиска (например, в каком-то внутреннем поле), 
продолжает сокращение рабочего диапазона, корректируя Left и Right.
Если Left и Right совпали (или если не совпали, а разница между Left и Right всего один элемент), 
также фиксируем завершение поиска.
Если поиск закончен, метод Step() ничего не делает.

Метод int GetResult() возвращает:
0, если процесс поиска ещё продолжается;
+1 если элемент был найден;
-1 если элемент не был найден.

Решение: BinarySearch

